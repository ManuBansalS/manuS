{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManuBansalS/manuS/blob/main/ResearchPaper/jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core libraries\n",
        "import os, random, re, string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# NLP\n",
        "import nltk, spacy\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Transformers\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "\n",
        "# Visualization\n",
        "import seaborn as sns\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "qZbX5j-zbdIE"
      },
      "id": "qZbX5j-zbdIE",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Optional: Still set environment variables for Kaggle if needed elsewhere\n",
        "os.environ['KAGGLE_USERNAME'] = \"manubansalg\"\n",
        "os.environ['KAGGLE_KEY'] = \"aa9b0c66c740f641bd7d2a35cdd58660\"\n",
        "\n",
        "# Dataset reference (as in Code 2)\n",
        "dataset_name = \"thoughtvector/customer-support-on-twitter\"\n",
        "\n",
        "# Specify the internal file name—typically the CSV inside the dataset.\n",
        "# The Kaggle dataset likely contains a CSV (often named something like 'customer_support_on_twitter.csv')\n",
        "file_path = \"twcs/twcs.csv\"\n",
        "\n",
        "# Load dataset directly into pandas DataFrame\n",
        "df = kagglehub.load_dataset(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    dataset_name,\n",
        "    file_path\n",
        ")\n",
        "\n",
        "# Select only desired columns and drop missing values\n",
        "df = df[['text', 'author_id']]  # Adjust as needed—e.g., if 'label' exists instead of 'author_id'\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGDkX775c8-Y",
        "outputId": "4ab5a8ca-c065-47d9-8f8a-2da7ec35b45f"
      },
      "id": "wGDkX775c8-Y",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2041554325.py:18: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text   author_id\n",
            "0  @115712 I understand. I would like to assist y...  sprintcare\n",
            "1      @sprintcare and how do you propose we do that      115712\n",
            "2  @sprintcare I have sent several private messag...      115712\n",
            "3  @115712 Please send us a Private Message so th...  sprintcare\n",
            "4                                 @sprintcare I did.      115712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def fast_sentiment(text):\n",
        "    score = sia.polarity_scores(str(text))['compound']\n",
        "    if score >= 0.05:\n",
        "        return \"positive\"\n",
        "    elif score <= -0.05:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "df['sentiment'] = df['text'].apply(fast_sentiment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y65rJnydWFo",
        "outputId": "6e3344ff-f169-4f60-9671-59310ccf92d0"
      },
      "id": "8Y65rJnydWFo",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"http\\S+\", \"\", str(text))  # remove URLs\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = \" \".join([word for word in text.split() if word not in STOPWORDS])\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df['text'].astype(str).apply(clean_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KvEuzt6i-4a",
        "outputId": "2aa45ac0-0cbd-43c3-ce02-5d8c26b1ce4b"
      },
      "id": "5KvEuzt6i-4a",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# First split into train (80%) and temp (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    df['clean_text'],\n",
        "    df['sentiment'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['sentiment']\n",
        ")\n",
        "\n",
        "# Then split the temp (20%) into validation (10%) and test (10%)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp,\n",
        "    y_temp,\n",
        "    test_size=0.5,   # half of 20% → 10%\n",
        "    random_state=42,\n",
        "    stratify=y_temp\n",
        ")\n"
      ],
      "metadata": {
        "id": "a7pgd0Cpj7Vg"
      },
      "id": "a7pgd0Cpj7Vg",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_val_tfidf   = tfidf.transform(X_val)\n",
        "X_test_tfidf  = tfidf.transform(X_test)\n",
        "\n",
        "# Logistic Regression\n",
        "logreg = LogisticRegression(max_iter=1000, random_state=SEED)\n",
        "\n",
        "# 5-fold CV on train set with multiple metrics\n",
        "scoring = {'f1_macro': 'f1_macro', 'accuracy': 'accuracy'}\n",
        "cv_results = cross_validate(logreg, X_train_tfidf, y_train, cv=5, scoring=scoring)\n",
        "\n",
        "print(\"LogReg CV F1 Scores:\", cv_results['test_f1_macro'], \"Mean:\", cv_results['test_f1_macro'].mean())\n",
        "print(\"LogReg CV Accuracy Scores:\", cv_results['test_accuracy'], \"Mean:\", cv_results['test_accuracy'].mean())\n",
        "\n",
        "# Train & evaluate on test set\n",
        "logreg.fit(X_train_tfidf, y_train)\n",
        "y_pred = logreg.predict(X_test_tfidf)\n",
        "print(\"LogReg Test Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWuKUSvBlO3Q",
        "outputId": "9fc1af2c-a174-41a2-b756-902b3bb0517f"
      },
      "id": "LWuKUSvBlO3Q",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogReg CV F1 Scores: [0.87592994 0.87639213 0.87625138 0.875895   0.87599375] Mean: 0.8760924418280286\n",
            "LogReg CV Accuracy Scores: [0.89154538 0.89208329 0.89185657 0.89149425 0.89164738] Mean: 0.8917253743842342\n",
            "LogReg Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.77      0.81     66002\n",
            "     neutral       0.86      0.92      0.89     72447\n",
            "    positive       0.92      0.93      0.93    142729\n",
            "\n",
            "    accuracy                           0.89    281178\n",
            "   macro avg       0.88      0.87      0.88    281178\n",
            "weighted avg       0.89      0.89      0.89    281178\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Linear SVM\n",
        "svm = LinearSVC(random_state=SEED)\n",
        "\n",
        "# 5-fold CV with multiple metrics\n",
        "scoring = {'f1_macro': 'f1_macro', 'accuracy': 'accuracy'}\n",
        "cv_results = cross_validate(svm, X_train_tfidf, y_train, cv=5, scoring=scoring)\n",
        "\n",
        "print(\"SVM CV F1 Scores:\", cv_results['test_f1_macro'], \"Mean:\", cv_results['test_f1_macro'].mean())\n",
        "print(\"SVM CV Accuracy Scores:\", cv_results['test_accuracy'], \"Mean:\", cv_results['test_accuracy'].mean())\n",
        "\n",
        "# Train & evaluate on test set\n",
        "svm.fit(X_train_tfidf, y_train)\n",
        "y_pred = svm.predict(X_test_tfidf)\n",
        "print(\"SVM Test Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SPZ0G40sE4b",
        "outputId": "dee933cc-ee41-4fc3-9300-a08996296630"
      },
      "id": "0SPZ0G40sE4b",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM CV F1 Scores: [0.87703725 0.87731334 0.87690997 0.87667114 0.87711301] Mean: 0.8770089421607092\n",
            "SVM CV Accuracy Scores: [0.89276125 0.89305465 0.89261676 0.89244339 0.89281213] Mean: 0.8927376358404082\n",
            "SVM Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.77      0.81     66002\n",
            "     neutral       0.86      0.92      0.89     72447\n",
            "    positive       0.92      0.94      0.93    142729\n",
            "\n",
            "    accuracy                           0.89    281178\n",
            "   macro avg       0.88      0.87      0.88    281178\n",
            "weighted avg       0.89      0.89      0.89    281178\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3XoQ1d3zTwl",
        "outputId": "b5df0ed0-482d-4e43-9928-7cd84f1ec219"
      },
      "id": "l3XoQ1d3zTwl",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PEFT + Accelerate + Transformers\n",
        "!pip install -q transformers datasets peft accelerate"
      ],
      "metadata": {
        "id": "0huH26G29Z24"
      },
      "id": "0huH26G29Z24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "# ✅ Device check\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# =========================\n",
        "# 1. Prepare Dataset\n",
        "# =========================\n",
        "# Encode string labels -> integers\n",
        "encoder = LabelEncoder()\n",
        "y_train_enc = encoder.fit_transform(y_train)\n",
        "y_val_enc   = encoder.transform(y_val)\n",
        "y_test_enc  = encoder.transform(y_test)\n",
        "\n",
        "train_dataset = Dataset.from_pandas(pd.DataFrame({\"text\": X_train, \"label\": y_train_enc}))\n",
        "val_dataset   = Dataset.from_pandas(pd.DataFrame({\"text\": X_val, \"label\": y_val_enc}))\n",
        "test_dataset  = Dataset.from_pandas(pd.DataFrame({\"text\": X_test, \"label\": y_test_enc}))\n",
        "\n",
        "# =========================\n",
        "# 2. Load DistilBERT + Tokenizer\n",
        "# =========================\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "\n",
        "# =========================\n",
        "# 3. Apply LoRA (PEFT)\n",
        "# =========================\n",
        "config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,   # sequence classification\n",
        "    r=16,                         # rank\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(base_model, config)\n",
        "model.to(device)\n",
        "\n",
        "# =========================\n",
        "# 4. Tokenization\n",
        "# =========================\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize, batched=True)\n",
        "val_dataset   = val_dataset.map(tokenize, batched=True)\n",
        "test_dataset  = test_dataset.map(tokenize, batched=True)\n",
        "\n",
        "train_dataset = train_dataset.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "val_dataset   = val_dataset.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "test_dataset  = test_dataset.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "# =========================\n",
        "# 5. Training Arguments\n",
        "# =========================\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=32,  # fast on GPU\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,              # 3 epochs enough\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,                       # mixed precision for speed\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "    save_total_limit=1,\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 6. Metrics\n",
        "# =========================\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"macro_f1\": f1_score(labels, preds, average=\"macro\")\n",
        "    }\n",
        "\n",
        "# =========================\n",
        "# 7. Trainer\n",
        "# =========================\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 8. Train\n",
        "# =========================\n",
        "trainer.train()\n",
        "\n",
        "# =========================\n",
        "# 9. Evaluation\n",
        "# =========================\n",
        "print(\"\\nValidation Results:\")\n",
        "val_results = trainer.evaluate(val_dataset)\n",
        "print(val_results)\n",
        "\n",
        "print(\"\\nTest Results:\")\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "print(test_results)\n",
        "\n",
        "# Predictions + classification report\n",
        "predictions = trainer.predict(test_dataset)\n",
        "y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "y_true = predictions.label_ids\n",
        "\n",
        "print(\"\\nLoRA-DistilBERT Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"LoRA-DistilBERT Macro-F1:\", f1_score(y_true, y_pred, average='macro'))\n",
        "print(\"LoRA-DistilBERT Classification Report:\\n\", classification_report(y_true, y_pred, target_names=encoder.classes_))\n"
      ],
      "metadata": {
        "id": "lLcoi9SkDW__"
      },
      "id": "lLcoi9SkDW__",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}