{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManuBansalS/manuS/blob/main/ResearchPaper/jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core libraries\n",
        "import os, random, re, string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# NLP\n",
        "import nltk, spacy\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Transformers\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "\n",
        "# Visualization\n",
        "import seaborn as sns\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "qZbX5j-zbdIE"
      },
      "id": "qZbX5j-zbdIE",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Optional: Still set environment variables for Kaggle if needed elsewhere\n",
        "os.environ['KAGGLE_USERNAME'] = \"manubansalg\"\n",
        "os.environ['KAGGLE_KEY'] = \"aa9b0c66c740f641bd7d2a35cdd58660\"\n",
        "\n",
        "# Dataset reference (as in Code 2)\n",
        "dataset_name = \"thoughtvector/customer-support-on-twitter\"\n",
        "\n",
        "# Specify the internal file name—typically the CSV inside the dataset.\n",
        "# The Kaggle dataset likely contains a CSV (often named something like 'customer_support_on_twitter.csv')\n",
        "file_path = \"twcs/twcs.csv\"\n",
        "\n",
        "# Load dataset directly into pandas DataFrame\n",
        "df = kagglehub.load_dataset(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    dataset_name,\n",
        "    file_path\n",
        ")\n",
        "\n",
        "# Select only desired columns and drop missing values\n",
        "df = df[['text', 'author_id']]  # Adjust as needed—e.g., if 'label' exists instead of 'author_id'\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGDkX775c8-Y",
        "outputId": "1e8bda04-097d-4a05-eeee-253710c1e2bc"
      },
      "id": "wGDkX775c8-Y",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2041554325.py:18: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text   author_id\n",
            "0  @115712 I understand. I would like to assist y...  sprintcare\n",
            "1      @sprintcare and how do you propose we do that      115712\n",
            "2  @sprintcare I have sent several private messag...      115712\n",
            "3  @115712 Please send us a Private Message so th...  sprintcare\n",
            "4                                 @sprintcare I did.      115712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def fast_sentiment(text):\n",
        "    score = sia.polarity_scores(str(text))['compound']\n",
        "    if score >= 0.05:\n",
        "        return \"positive\"\n",
        "    elif score <= -0.05:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "df['sentiment'] = df['text'].apply(fast_sentiment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y65rJnydWFo",
        "outputId": "9321870e-f9ca-4c3b-91d7-b50ac9d186ef"
      },
      "id": "8Y65rJnydWFo",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"http\\S+\", \"\", str(text))  # remove URLs\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = \" \".join([word for word in text.split() if word not in STOPWORDS])\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df['text'].astype(str).apply(clean_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KvEuzt6i-4a",
        "outputId": "cd3c0e7b-cf1c-48a8-9f2a-d914e5298543"
      },
      "id": "5KvEuzt6i-4a",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# First split into train (80%) and temp (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    df['clean_text'],\n",
        "    df['sentiment'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['sentiment']\n",
        ")\n",
        "\n",
        "# Then split the temp (20%) into validation (10%) and test (10%)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp,\n",
        "    y_temp,\n",
        "    test_size=0.5,   # half of 20% → 10%\n",
        "    random_state=42,\n",
        "    stratify=y_temp\n",
        ")\n"
      ],
      "metadata": {
        "id": "a7pgd0Cpj7Vg"
      },
      "id": "a7pgd0Cpj7Vg",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_val_tfidf   = tfidf.transform(X_val)\n",
        "X_test_tfidf  = tfidf.transform(X_test)\n",
        "\n",
        "# Logistic Regression\n",
        "logreg = LogisticRegression(max_iter=1000, random_state=SEED)\n",
        "\n",
        "# 5-fold CV on train set\n",
        "cv_scores = cross_val_score(logreg, X_train_tfidf, y_train, cv=5, scoring='f1_macro')\n",
        "print(\"LogReg CV F1 Scores:\", cv_scores, \"Mean:\", cv_scores.mean())\n",
        "\n",
        "# Train & evaluate\n",
        "logreg.fit(X_train_tfidf, y_train)\n",
        "y_pred = logreg.predict(X_test_tfidf)\n",
        "print(\"LogReg Test Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWuKUSvBlO3Q",
        "outputId": "264a024d-a0ca-4cbd-e4ec-0fa3ec4dd540"
      },
      "id": "LWuKUSvBlO3Q",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogReg CV F1 Scores: [0.87592994 0.87639213 0.87625138 0.875895   0.87599375] Mean: 0.8760924418280286\n",
            "LogReg Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.77      0.81     66002\n",
            "     neutral       0.86      0.92      0.89     72447\n",
            "    positive       0.92      0.93      0.93    142729\n",
            "\n",
            "    accuracy                           0.89    281178\n",
            "   macro avg       0.88      0.87      0.88    281178\n",
            "weighted avg       0.89      0.89      0.89    281178\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear SVM\n",
        "svm = LinearSVC(random_state=SEED)\n",
        "\n",
        "# 5-fold CV\n",
        "cv_scores = cross_val_score(svm, X_train_tfidf, y_train, cv=5, scoring='f1_macro')\n",
        "print(\"SVM CV F1 Scores:\", cv_scores, \"Mean:\", cv_scores.mean())\n",
        "\n",
        "# Train & evaluate\n",
        "svm.fit(X_train_tfidf, y_train)\n",
        "y_pred = svm.predict(X_test_tfidf)\n",
        "print(\"SVM Test Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SPZ0G40sE4b",
        "outputId": "06129f6c-a253-4fbf-eb70-32651ff3433b"
      },
      "id": "0SPZ0G40sE4b",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM CV F1 Scores: [0.87703725 0.87731334 0.87690997 0.87667114 0.87711301] Mean: 0.8770089421607092\n",
            "SVM Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.77      0.81     66002\n",
            "     neutral       0.86      0.92      0.89     72447\n",
            "    positive       0.92      0.94      0.93    142729\n",
            "\n",
            "    accuracy                           0.89    281178\n",
            "   macro avg       0.88      0.87      0.88    281178\n",
            "weighted avg       0.89      0.89      0.89    281178\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Device check\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# 2) Use DistilBERT (smaller & faster)\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"  # already fine-tuned for sentiment\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Enable half precision for speed/memory\n",
        "model.half()\n",
        "\n",
        "# 3) Prediction function (optimized for 4GB VRAM)\n",
        "@torch.inference_mode()\n",
        "def predict_labels(texts, batch_size=16, max_length=128):\n",
        "    preds, confs = [], []\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"BERT inference\"):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        enc = tokenizer(\n",
        "            batch,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        outputs = model(**enc)\n",
        "        probs = torch.softmax(outputs.logits, dim=-1)\n",
        "        conf, ids = torch.max(probs, dim=-1)\n",
        "        preds.extend(ids.cpu().numpy())\n",
        "        confs.extend(conf.cpu().numpy())\n",
        "    return preds, confs\n",
        "\n",
        "# 4) Run on Validation and Test\n",
        "# (assuming you already have X_val, X_test, y_val, y_test from earlier splits)\n",
        "\n",
        "# Convert to list\n",
        "val_texts = list(X_val)\n",
        "test_texts = list(X_test)\n",
        "\n",
        "# Predict\n",
        "val_preds, _ = predict_labels(val_texts, batch_size=16)\n",
        "test_preds, _ = predict_labels(test_texts, batch_size=16)\n",
        "\n",
        "# Map y_val/y_test (strings) into numeric: 0=NEG,1=POS\n",
        "# DistilBERT-SST2 only has NEG/POS (no NEUTRAL)\n",
        "# We'll map: negative→0, positive→1, neutral→closest (0 for safety)\n",
        "def map_labels(lbls):\n",
        "    mapped = []\n",
        "    for l in lbls:\n",
        "        if str(l).lower().startswith(\"neg\"):\n",
        "            mapped.append(0)\n",
        "        elif str(l).lower().startswith(\"pos\"):\n",
        "            mapped.append(1)\n",
        "        else:\n",
        "            mapped.append(0)  # treat neutral as negative for SST-2\n",
        "    return mapped\n",
        "\n",
        "y_val_mapped = map_labels(y_val)\n",
        "y_test_mapped = map_labels(y_test)\n",
        "\n",
        "# Metrics\n",
        "print(\"\\nValidation Evaluation:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val_mapped, val_preds))\n",
        "print(\"Macro-F1:\", f1_score(y_val_mapped, val_preds, average=\"macro\"))\n",
        "print(\"Classification Report:\\n\", classification_report(y_val_mapped, val_preds, target_names=[\"negative\",\"positive\"]))\n",
        "\n",
        "print(\"\\nTest Evaluation:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_mapped, test_preds))\n",
        "print(\"Macro-F1:\", f1_score(y_test_mapped, test_preds, average=\"macro\"))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_mapped, test_preds, target_names=[\"negative\",\"positive\"]))\n",
        "\n",
        "# 5) (Optional) Run on full dataset\n",
        "# This will take a few hours on GTX 1650\n",
        "all_preds, all_confs = predict_labels(df['clean_text'].tolist(), batch_size=16)\n",
        "df['bert_label'] = all_preds\n",
        "df['bert_conf'] = all_confs\n",
        "df.to_csv(\"bert_sentiment_full.csv\", index=False)\n",
        "print(\"Saved full dataset predictions to bert_sentiment_full.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLcoi9SkDW__",
        "outputId": "64d8b7f8-b322-4094-c397-0ea363197943"
      },
      "id": "lLcoi9SkDW__",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running DistilBERT on Validation set...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}