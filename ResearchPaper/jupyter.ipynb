{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManuBansalS/manuS/blob/main/ResearchPaper/jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core libraries\n",
        "import os, random, re, string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# NLP\n",
        "import nltk, spacy\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Transformers\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "\n",
        "# Visualization\n",
        "import seaborn as sns\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "qZbX5j-zbdIE"
      },
      "id": "qZbX5j-zbdIE",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Optional: Still set environment variables for Kaggle if needed elsewhere\n",
        "os.environ['KAGGLE_USERNAME'] = \"manubansalg\"\n",
        "os.environ['KAGGLE_KEY'] = \"aa9b0c66c740f641bd7d2a35cdd58660\"\n",
        "\n",
        "# Dataset reference (as in Code 2)\n",
        "dataset_name = \"thoughtvector/customer-support-on-twitter\"\n",
        "\n",
        "# Specify the internal file name—typically the CSV inside the dataset.\n",
        "# The Kaggle dataset likely contains a CSV (often named something like 'customer_support_on_twitter.csv')\n",
        "file_path = \"twcs/twcs.csv\"\n",
        "\n",
        "# Load dataset directly into pandas DataFrame\n",
        "df = kagglehub.load_dataset(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    dataset_name,\n",
        "    file_path\n",
        ")\n",
        "\n",
        "# Select only desired columns and drop missing values\n",
        "df = df[['text', 'author_id']]  # Adjust as needed—e.g., if 'label' exists instead of 'author_id'\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGDkX775c8-Y",
        "outputId": "ae2df45a-512e-4f61-c734-1ffdd21b3987"
      },
      "id": "wGDkX775c8-Y",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2041554325.py:18: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text   author_id\n",
            "0  @115712 I understand. I would like to assist y...  sprintcare\n",
            "1      @sprintcare and how do you propose we do that      115712\n",
            "2  @sprintcare I have sent several private messag...      115712\n",
            "3  @115712 Please send us a Private Message so th...  sprintcare\n",
            "4                                 @sprintcare I did.      115712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def fast_sentiment(text):\n",
        "    score = sia.polarity_scores(str(text))['compound']\n",
        "    if score >= 0.05:\n",
        "        return \"positive\"\n",
        "    elif score <= -0.05:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "df['sentiment'] = df['text'].apply(fast_sentiment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y65rJnydWFo",
        "outputId": "85cba3c0-5e5d-4bdf-c3c0-a6f0ec5df225"
      },
      "id": "8Y65rJnydWFo",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"http\\S+\", \"\", str(text))  # remove URLs\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = \" \".join([word for word in text.split() if word not in STOPWORDS])\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df['text'].astype(str).apply(clean_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KvEuzt6i-4a",
        "outputId": "a8192387-3d10-44d9-dd21-931136c81640"
      },
      "id": "5KvEuzt6i-4a",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# First split into train (80%) and temp (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    df['clean_text'],\n",
        "    df['sentiment'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['sentiment']\n",
        ")\n",
        "\n",
        "# Then split the temp (20%) into validation (10%) and test (10%)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp,\n",
        "    y_temp,\n",
        "    test_size=0.5,   # half of 20% → 10%\n",
        "    random_state=42,\n",
        "    stratify=y_temp\n",
        ")\n"
      ],
      "metadata": {
        "id": "a7pgd0Cpj7Vg"
      },
      "id": "a7pgd0Cpj7Vg",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_val_tfidf   = tfidf.transform(X_val)\n",
        "X_test_tfidf  = tfidf.transform(X_test)\n",
        "\n",
        "# Logistic Regression\n",
        "logreg = LogisticRegression(max_iter=1000, random_state=SEED)\n",
        "\n",
        "# 5-fold CV on train set\n",
        "cv_scores = cross_val_score(logreg, X_train_tfidf, y_train, cv=5, scoring='f1_macro')\n",
        "print(\"LogReg CV F1 Scores:\", cv_scores, \"Mean:\", cv_scores.mean())\n",
        "\n",
        "# Train & evaluate\n",
        "logreg.fit(X_train_tfidf, y_train)\n",
        "y_pred = logreg.predict(X_test_tfidf)\n",
        "print(\"LogReg Test Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWuKUSvBlO3Q",
        "outputId": "c94efab8-d64e-43e2-c855-907f600f9a50"
      },
      "id": "LWuKUSvBlO3Q",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogReg CV F1 Scores: [0.87613812 0.87638048 0.87603756 0.87597888 0.87598855] Mean: 0.8761047205830564\n",
            "LogReg Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.77      0.81     66002\n",
            "     neutral       0.86      0.92      0.89     72447\n",
            "    positive       0.92      0.93      0.93    142729\n",
            "\n",
            "    accuracy                           0.89    281178\n",
            "   macro avg       0.88      0.87      0.88    281178\n",
            "weighted avg       0.89      0.89      0.89    281178\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear SVM\n",
        "svm = LinearSVC(random_state=SEED)\n",
        "\n",
        "# 5-fold CV\n",
        "cv_scores = cross_val_score(svm, X_train_tfidf, y_train, cv=5, scoring='f1_macro')\n",
        "print(\"SVM CV F1 Scores:\", cv_scores, \"Mean:\", cv_scores.mean())\n",
        "\n",
        "# Train & evaluate\n",
        "svm.fit(X_train_tfidf, y_train)\n",
        "y_pred = svm.predict(X_test_tfidf)\n",
        "print(\"SVM Test Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SPZ0G40sE4b",
        "outputId": "f52dc6da-3e6b-4620-f628-1721a742ab04"
      },
      "id": "0SPZ0G40sE4b",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM CV F1 Scores: [0.87702563 0.87730269 0.87690973 0.87671309 0.87713654] Mean: 0.8770175350380214\n",
            "SVM Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.77      0.81     66002\n",
            "     neutral       0.86      0.92      0.89     72447\n",
            "    positive       0.92      0.94      0.93    142729\n",
            "\n",
            "    accuracy                           0.89    281178\n",
            "   macro avg       0.88      0.87      0.88    281178\n",
            "weighted avg       0.89      0.89      0.89    281178\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from joblib import Parallel, delayed\n",
        "import numpy as np\n",
        "\n",
        "# ✅ Encode labels\n",
        "encoder = LabelEncoder()\n",
        "y_train_enc = encoder.fit_transform(y_train)\n",
        "y_val_enc   = encoder.transform(y_val)\n",
        "y_test_enc  = encoder.transform(y_test)\n",
        "\n",
        "# ✅ Load lightweight pretrained DistilBERT (sentiment fine-tuned)\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "bert_classifier = pipeline(\"sentiment-analysis\", model=model_name, tokenizer=model_name, device=-1)  # -1 = CPU\n",
        "\n",
        "# Function to process one batch of texts\n",
        "def process_batch(batch_texts):\n",
        "    preds = bert_classifier(batch_texts, truncation=True)\n",
        "    labels = []\n",
        "    for p in preds:\n",
        "        if p[\"label\"].lower() in [\"positive\", \"label_2\"]:\n",
        "            labels.append(\"positive\")\n",
        "        elif p[\"label\"].lower() in [\"negative\", \"label_0\"]:\n",
        "            labels.append(\"negative\")\n",
        "        else:\n",
        "            labels.append(\"neutral\")\n",
        "    return labels\n",
        "\n",
        "# ✅ Parallelized prediction using joblib\n",
        "def parallel_predict(texts, n_jobs=4, batch_size=64):\n",
        "    batches = [texts[i:i+batch_size] for i in range(0, len(texts), batch_size)]\n",
        "    results = Parallel(n_jobs=n_jobs)(delayed(process_batch)(b) for b in batches)\n",
        "    return [label for batch in results for label in batch]\n",
        "\n",
        "# ----------------- Validation -----------------\n",
        "print(\"\\nRunning DistilBERT on Validation set...\")\n",
        "y_val_pred = parallel_predict(list(X_val), n_jobs=4, batch_size=64)\n",
        "print(\"\\nDistilBERT Validation Report:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(\"Macro-F1:\", f1_score(y_val, y_val_pred, average=\"macro\"))\n",
        "print(classification_report(y_val, y_val_pred, target_names=encoder.classes_))\n",
        "\n",
        "# ----------------- Test -----------------\n",
        "print(\"\\nRunning DistilBERT on Test set...\")\n",
        "y_test_pred = parallel_predict(list(X_test), n_jobs=4, batch_size=64)\n",
        "print(\"\\nDistilBERT Test Report:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"Macro-F1:\", f1_score(y_test, y_test_pred, average=\"macro\"))\n",
        "print(classification_report(y_test, y_test_pred, target_names=encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLcoi9SkDW__",
        "outputId": "64d8b7f8-b322-4094-c397-0ea363197943"
      },
      "id": "lLcoi9SkDW__",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running DistilBERT on Validation set...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}